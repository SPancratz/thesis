We present an overview of arithmetic operations in~$\mathbf{Q}_p$ 
and unramified extensions.  Much of the material is well-known in 
either the context of $p$-adic arithmetic, see e.g.\ 
Vercauteren~\citep[\S 12]{HEHCC2005}
or integer arithmetic, see e.g.\ the survey by Bernstein~\citep{Bernstein2008}. 
This work is accompanied by an implementation in the open-source 
computational software {\sc FLINT}~\citep{FLINT}.

The sections on the $p$-adic exponential and logarithm functions 
are joint work with Fredrik Johansson, RISC, Austria.

\section{Data format}

We represent a non-zero $p$-adic number $x \in \mathbf{Q}_p$ in the form 
\begin{equation}
x = p^v u
\end{equation}
where $u, v \in \mathbf{Z}$ and $u \nmid p$.  When working to precision~$N$, 
it is sometimes useful to assume that $u \in [0,p^{N-v})$.

When working in the unique unramified extension of $\mathbf{Q}_p$ of 
degree~$d$, we which shall refer to as $\mathbf{Q}_q$ with $q = p^d$, 
we choose to represent this as 
\begin{equation}
\mathbf{Q}_q \cong \mathbf{Q}_p[X] / (f(X))
\end{equation}
where $f(x) \bmod p$ is an irreducible and separable polynomial.  We store 
$f(X)$ as a sparse polynomial and assume that its coefficients are 
reduce modulo~$p$.  The sparsity assumption allows for reduction of a 
degree~$n$ polynomial modulo~$f(X)$ in time $\mathcal{O}(nd)$ multiplications 
and additions in $\mathbf{Q}_p \bmod p^N$.  Non-zero elements~$g$ in 
$\mathbf{Q}_q$ can be represented as 
\begin{equation}
g(X) = p^v h(X)
\end{equation}
where $v \in \mathbf{Z}$ and $h(X) \in \mathbf{Z}[X]$ is such that at least 
one coefficient of $h(X)$ is a $p$-adic unit.  As before, it can be useful 
to assume that all coefficients of $h(X)$ are reduced modulo $p^{N-v}$.

\begin{rem}
We could aim for a genuine base~$p$ representation, explicitly showing 
the $p$-adic digits in the form 
\begin{equation}
x = p^v (a_0 + a_1 p + a_2 p^2 + \dotsb) 
\end{equation}
with $a_i \in [0,p)$ for all $i$, or perhaps 
\begin{equation}
x = p^v (a_0 + a_1 p^k + a_2 p^{2k} + \dotsb)
\end{equation}
with $a_i \in [0,p^k)$ where $k$ is least such that $p^{k}$ fits into 
a machine word.
This data format would be beneficial to many algorithms.  But in practice, 
given the high quality and architecture specific details of implementations 
for arbitrary precision integer arithmetic in base~$2$, this approach does 
not seem favourable.
\end{rem}

\begin{rem}
Eventually, the case $p = 2$ shold be handled separated manner.
\end{rem}

\section{Hensel lifting}

\begin{thm} \label{thm:Hensel1}
Let $g \in \mathbf{Z}_q[X]$ be a polynomial whose leading coefficient 
is a unit and suppose that $x_0 \in \mathbf{Z}_q$ is such that 
\begin{equation*}
\ord_p(g(x_0)) \geq m + n, \quad \ord_p(g'(x_0)) \leq m
\end{equation*}
for some $0 \leq m < n$.  Then there exists a unique $x \in \mathbf{Z}_q$ 
such that $g(x) = 0$ and $x \equiv x_0 \pmod{p^n}$.
\end{thm}

\begin{proof}
We construct a sequence $(x_k)$ such that 
\begin{align*}
\ord_p(g(x_k)) & \geq 2^k (n - m) + 2m, \\
\ord_p(g'(x_k)) & \leq m, \\
\ord_p(x_{k+1} - x_k) & \geq 2^k (n-m) + m, 
\end{align*}
where the choice of $x_{k+1}$ is unique given $x_k$, for $k \geq 0$.  
As the sequence $(x_k)$ is Cauchy, the result then follows taking 
$x = \lim_{k \to \infty} x_k$ and using the continuity of $g$ to 
establish $g(x) = 0$.

In order to satisfy the last condition, begin by writing 
$x_{k+1} = x_k + p^{2^k(n-m) + m} T$ and expand $g(x_{k+1})$ 
as a Taylor series about $x_k$, 
\begin{align*}
g(x_{k+1}) & = \sum_{j=0}^{\deg(g)} \frac{g^{(j)}(x_k)}{j!} p^{(2^k(n-m) + m) j} T^j \\
           & \equiv g(x_k) + g'(x_k) p^{2^k(n-m) + m} T \pmod{p^{2^{k+1}(n-m)+2m}}
\end{align*}
where the last line follows upon observing that $g^{(j)}(x_k) / j!$ 
is $p$-adically integral for all~$j$.  This forces the unique choice 
$x_{k+1} = x_k - g(x_k) / g'(x_k)$ modulo~${p^{2^{k+1}(n-m) + m}}$.
\end{proof}

\begin{rem}
In order to approximate the root of a polynomial to a desired 
precision~$N$, it is preferable to choose the sequence of 
precisions 
\begin{equation*}
e_{k} = N, e_{k-1} = \ceil{(e_k + m) / 2}, \dotsc, 
e_0 = \ceil{(e_1 + m) / 2} \leq n
\end{equation*}
as this choice minimises the computational cost in the last 
step of the iteration.
\end{rem}

\begin{thm} \label{thm:Hensel2}
Let $g \in \mathbf{Z}_q[X]$ be a polynomial whose leading coefficient 
is a unit and suppose that $x_0 \in \mathbf{Z}_q$ is such that 
\begin{equation*}
\ord_p(g(x_0)) \geq m + n, \quad \ord_p(g'(x_0)) \leq m
\end{equation*}
for some $0 \leq m < n$.  Moreover, let $x$ be the unique root of $g$ 
lifting $x_0$ and define the sequences
\begin{align*}
y_0 & = \bigl( g'(x_0) \bigr)^{-1}, \\
x_{k+1} & = x_k - g(x_k) y_k, \\
y_{k+1} & = y_k \bigl( 2 - y_k g'(x_{k+1}) \bigr),
\end{align*}
where $x_k$, $y_k$ are computed to $p$-adic precision $2^k (n-m) + m$.
Then $x_k$ agrees with $x$ modulo~$p^{2^k (n - m) + m}$.
\end{thm}

\begin{rem}
The above theorem leads to an algorithm running two Hensel lifting 
procedures in parallel, which is favourable to the approach suggested 
by the expression $x_{k+1} = x_k - g(x_k) / g'(x_k)$ in 
Theorem~\ref{thm:Hensel1}, which leads to a nested lifting routine to 
compute the inverse of $g'(x_k)$ from scratch at each step.
\end{rem}

\section{Review of complexity results}

We let $\mathcal{O}(M(N))$ denote the complexity of multiplying two 
$N$-bit integers.  For example, the Sch\"onhage--Strassen algorithm 
allows us to take $M(N) = N \log N \log \log N$.  The same 
complexity can also be achieved for the division with remainder of 
a $2N$-bit integer by an $N$-bit integer.

As elements of $\mathbf{Z} / (p^N)$ are of bit size $N \log p$, 
multiplication of two numbers in $[0, p^N)$, with or without a subsequent 
reduction modulo $p^N$, has complexity $\mathcal{O}(M(N \log p))$ or 
$\mathcal{O}_p(M(N))$.

The multiplication of two elements of $\mathbf{Z}_q$ modulo $p^N$ 
involves one multiplication of two degree $d-1$ polynomials in 
$\mathbf{Z}/(p^N)$ and one reduction of a degree $2d - 2$ polynomial 
in $\bigl( \mathbf{Z}/(p^N)[X] \bigr) / (f(X))$.   Using a Fast Fourier 
Transform based multiplication routine, the polynomial product requires 
$\mathcal{O}(d \log d)$ operations in $\mathbf{Z}/(p^N)$, hence has 
complexity $\mathcal{O}(M(N \log p) d \log d)$.  The reduction modulo $f(X)$ 
requires $\mathcal{O}(d)$ operations in $\mathbf{Z}/(p^N)$ when $f(X)$ is 
sparse and has a bounded number of non-zero coefficients, and it requires 
$\mathcal{O}(d \log d)$ operations in $\mathbf{Z}/(p^N)$ when $f(X)$ is 
a dense polynomial.  In either case, the overall complexity of multiplication 
in $\mathbf{Z}_q$ modulo $p^N$ is given by $\mathcal{O}(M(N \log p) d \log d)$.

\section{Addition, subtraction, negation}

To add $x_0, x_1 \in \mathbf{Q}_q$ to precision~$N$, we compute 
\begin{equation}
x_0 + x_1 = p^{v_0} (u_0 + p^{v_1 - v_0} u_1)
\end{equation}
where we assume $v_0 \leq v_1$.  In general, the second factor 
will have to be reduced modulo $p^{N - v_0}$ using a division 
routine.  We can improve on this if we add the assumption that 
the input is reduced modulo $p^N$, in which case we observe that 
there the reduction can be facilitated by subtracting at most 
one multiple of~$p$.

\section{Multiplication}

To multiply $x_0, x_1 \in \mathbf{Q}_q$ to precision~$N$, we compute 
\begin{equation}
x_0 x_1 = p^{v_0 + v_1} u_0 u_1
\end{equation}
reducing the product of units $u_0 u_1$ modulo $p^{N - v_0 - v_1}$.

\section{Inversion}

In order to compute the inverse of $x \in \mathbf{Z}_q^{\times}$, we 
apply Hensel lifting on the polynomial $g(X) = 1 - x X$, leading to 
the iteration
\begin{equation}
x_{k + 1} = x_k - x_k (x_k x - 1),
\end{equation}
starting from an approximation modulo~$p$.

Inverses modulo over finite fields can be computed efficiently by 
extended greatest common divisor algorithms, for example, using 
Euclid's algorithm or the asymptotically fast Half-GCD 
algorithm~\citep{ThullYap1990} depending on the problem size.  
In either case, an improvement to the general method can be made 
computing only one cofactor, that 
is, when computing $s, t$ such that $1 = \gcd(a,b) = sa + tb$ 
we in fact only require one of the two cofactors $s, t$.

\section{Inverse square root}

The method of computing $p$-adic inverse square roots turns out 
to be interesting because it will be used as a precursor in computing 
$p$-adic square roots.

Given a non-zero $x = p^v u \in \mathbf{Q}_q$ where $v = \ord_p(x)$ 
$u \in \mathbf{Z}_q^{\times}$, the task is to compute its inverse 
square roots $x^{-1/2} = p^{-v/2} u^{-1/2}$.  Necessarily, we require 
that $v$ is even and $u$ a square in $\mathbf{Z}_q^{\times}$.

The computation then reduces to computing $p$-adic inverse square 
roots of $x \in \mathbf{Z}_q^{\times}$, which can be carried out 
using a Hensel lifting approach on $g(X) = 1 - x X^2$.  This leads 
to the almost division-free iteration
\begin{equation}
\begin{split}
x_{k+1} & = x + (1 - x x_k^2) / (2 x x_k) \\
        & = x + x_k (1 - x x_k^2) / 2
\end{split}
\end{equation}
In the notation of Theorem~\ref{thm:Hensel1}, this means that when 
$p = 2$ we can take $m = 1$, $n = 2$, and when $p > 2$ is an odd prime, 
we have $m = 0$, $n = 1$.

We observe that this iteration does indeed not require computationally 
intensive $p$-adic inversions.  When $p$ is odd, either the numerator 
is divisible by~$2$ as an integer, or we can add an appropriate (odd) 
power of~$p$ to this, yielding an even integer representative of the 
same value.  The division by~$2$ is then simply a bitshift.  When $p = 2$, 
the result on Hensel lifting in Theorem~\ref{thm:Hensel1} guarantees that 
the numerator is always divisible by~$2$ and the loss of precision is 
accounted for in the sequence of precisions.

When $p = 2$, we can obtain an initial approximation as follows. 
Let $s = (x \bmod 2)^{-1/2} \pmod{2}$.  If there exists a solution~$t$ 
to $t^2 + s t \equiv (1/x - s^2) / 4 \pmod{2}$ then $x_0 = s + 2 t$ 
is an approximate inverse square root of $x$ to precision~$2$, 
otherwise $x$ is not a square modulo~$8$ and hence not 
in~$\mathbf{Z}_q^{\times}$.  When $p > 2$ is an odd prime, we can 
take the inverse square root modulo~$p$ as our initial approximation.

The topic of computing square roots in finite fields is outside 
the scope of this discussion.  We refer the reader to standard 
results in finite field arithmetic, as presented e.g.\ in 
Bach--Shallit~\citep{Bac96}.

\section{Square root}

We observe that $x = p^v u \in \mathbf{Q}_q^{\times}$ has a square 
root if and only if $v$ is even and $u \in \mathbf{Z}_q^{\times}$ is 
a square.  Thus, for the remaining part of the discussion we may 
assume that $x \in \mathbf{Z}_q^{\times}$ is a square.

In order to compute $\sqrt{x} \bmod p^N$, we can use the previous method 
for computing the inverse square root to precision~$N$ and then multiply 
the result by~$x$.

As noted by Karp and Markstein~\citep{KarpMarkstein1997}, this algorithm 
can be improved by replacing the final iteration in the Hensel lifting 
procedure for the inverse square root by 
\begin{equation}
x_{k+1} = x_k (2 x - x_k^2) \pmod{p^N}
\end{equation}
and omitting the subsequent multiplication by~$x$ mentioned above.

\section{Teichm\"uller lift}

Recall that $\mathbf{Q}_q$ contains exactly $q$~elements that are 
$(q-1)$th roots of unity, above each element of the residue field 
$\mathbf{F}_q$.  The Teichm\"uller lift of an element $x \in \mathbf{F}_q$ 
is defined to be the unique lift to a $(q-1)$th root of unity 
in~$\mathbf{Q}_q$.

Over $\mathbf{Z}_p$, we apply Hensel lifting on $g(X) = X^p - X$, 
starting with $x_0 = x \bmod p$ and noting that $\ord_p(g'(x)) = 0$. 

\begin{rem}
The first improvement to the generic Hensel lifting routine 
is to utilise Theorem~\ref{thm:Hensel2} to compute the inverse 
of $g'(x_{\bullet})$ in parallel.

Secondly, we observe that in the first step we want to set 
$x_0 = x$, $y_0 = \bigl((p-1) x^{p-2}\bigr)^{-1}$ modulo~$p$ 
so we can set $y_0 = p - x_0$ without an inversion.
\end{rem}

Over $\mathbf{Q}_q$, we similarly apply the Hensel lifting routine 
on $g(X) = X^q - X$, starting from $x_0 = x \bmod p$.  We observe 
that the occurring denominators $g'(x_i) = q x_i^{q-1} - 1$ are 
approximations of $q - 1$, which is defined already over $\mathbf{Q}_p$.

\section{Frobenius}

Let $\Sigma \in \Gal(\mathbf{Q}_q/\mathbf{Q}_p) \cong \Gal(\mathbf{F}_q/\mathbf{F}_p)$ 
be the lift of $\sigma \colon \mathbf{F}_q \mapsto \mathbf{F}_q, x \mapsto x^p$. 
For any $x \in \mathbf{Q}_q$ and $k \in \mathbf{Z}$, we aim to compute $\Sigma^k x$ 
modulo $p^N$, noting that $\Sigma$ has order~$d$.  As such, we may assume that~$d$ 
is reduced modulo~$d$, and in fact that $0 < k < d$ as $\Sigma^0$ is the identity map.

Let $x = \sum_{i=0}^{d-1} a_i X^i$ in $\mathbf{Q}_p[X]/(f(X))$.  
As $\Sigma$ is a $\mathbf{Q}_p$-linear map, we may assume that 
$x \in \mathbf{Z}_q^{\times}$.

First, we can compute $\Sigma^k X$ using Hensel lifting on $f(X)$, 
starting from $x_0 = X^{p^k}$ in $\mathbf{F}_p[X] / (f(X))$ and 
being careful to take the $p$-adic valuation of $f'(x_0)$ into 
account in the Hensel lifting routine.

Then, we compute $\Sigma^k x = \sum_{i=0}^{d-1} a_i (\Sigma^k X)^i$, 
which entails a polynomial composition modulo~$f(X)$ and~$p^N$.

\begin{rem}
In a first approach, we might use Horner's method to carry out the 
composition, which requires about $d$ multiplications in $\mathbf{Q}_q$.
However, we can use a rectangular splitting approach instead, starting 
from the expression 
\begin{equation}
x = \sum_{j=0}^{\floor{d/B}-1} \Bigl( \sum_{i=0}^{B-1} a_{i+Bj} X^i  \Bigr) X^{Bj}
\end{equation}
where $B = \floor{\sqrt{d}}$, precomputing $\Sigma^k(X)^i$ for $i = 0, \dotsc, B$. 
This only requires about $2 \sqrt{d}$ multiplications in $\mathbf{Q}_q$ 
but additional space for about $d^{3/2}$ elements of $\mathbf{Z}/(p^N)$.
\end{rem}

\section{Trace}

The image of $x \in \mathbf{Q}_q$ under the trace function 
$\Trace_{\mathbf{Q}_q/\mathbf{Q}_p}(x) \colon \mathbf{Q}_q \to \mathbf{Q}_p$ 
is defined as the sum of the Galois conjugates of~$x$.  Equivalently, 
it is defined as the trace of the $\mathbf{Q}_p$-linear map on 
$\mathbf{Q}_q$ given by multiplication by~$x$.  As the trace map 
itself is $\mathbf{Q}_p$-linear, we may now assume that 
$x \in \mathbf{Z}_q^{\times}$.

There are two efficient ways to compute this:

We can compute this from the definition of $\Trace(-)$ by reducing 
$x X^i$ modulo $f(X)$ and forming the sum of the $X^i$-coordinates, 
for $i = 0, \dotsc, d - 1$.

Recalling that the reduction of a degree~$2d-2$ polynomial modulo 
$f(X)$ requires $\mathcal{O}(d \log d)$ operations in $\mathbf{Z}/(p^N)$ 
it is clear that this approach takes time $\mathcal{O}_p(M(N) d^2 \log d)$. 
When we assume that $f(X)$ is sparse, this decreases to 
$\mathcal{O}_p(M(N) d^2)$.

Alternatively, we can observe that on writing $x = \sum_{i=0}^{d-1} a_i X^i$ 
we have $\Trace(x) = \sum_{i=0}^{d-1} a_i \Trace(X^i)$ and then use 
Newton's formula,
\begin{equation} \label{eq:03-03-trace}
\Trace(X^i) + \sum_{j=1}^{i-1} \Trace(X^{i-j}) f_{d-j} + i f_{d-i} = 0 \pmod{p^N}, 
\end{equation}
for $i = 1, \dotsc, d-1$, where $f(X) = \sum_{i=0}^{d-1} f_i X^i$.  
We also note that $\Trace(X^0) = \Trace(I) = d$.  This approach visibly 
requires time $\mathcal{O}_p(M(N) d^2)$ in general.  When $f(X)$ is 
sparse, this further decreases to $\mathcal{O}_p(M(N) d)$ as the 
sum in Equation~\eqref{eq:03-03-trace} has a bounded number of 
non-zero terms.

\section{Norm}

The image of $x \in \mathbf{Q}_q$ under the norm function 
$\Norm_{\mathbf{Q}_q/\mathbf{Q}_p} \colon \mathbf{Q}_q \to \mathbf{Q}_p$ 
is defined as the product of the Galois conjugates of~$x$.  As this 
is a $\mathbf{Q}_p$-linear map, we may assume that 
$x \in \mathbf{Z}_q^{\times}$.  Since 
$\Gal(\mathbf{Q}_q/\mathbf{Q}_p) = \langle \Sigma \rangle$ is cyclic 
of order~$d$, we find that, letting $a(X) \in \mathbf{Z}_p[X]$ denote 
the same polynomial as $x = \sum_{i=0}^{d-1} a_i X^i$, 
\begin{align}
\Norm_{\mathbf{Q}_q/\mathbf{Q}_p} (x) & = \prod_{i=0}^{d-1} \Sigma^i (x) \\
                                      & = \prod_{i=0}^{d-1} a(\Sigma^i(X)) \\
                                      & = \ell(f)^{- \deg(a)} \Res(f(X), a(X)).
\end{align}
where $\ell(f)$ denotes the leading coefficient of $f(X)$.  

Whenever $x \in \mathbf{Z}_q^{\times}$ satisfies $\ord_p(x-1) > (p-1)^{-1}$ 
we can improve on this significantly, computing the norm via
\begin{equation}
\Norm_{\mathbf{Q}_q / \mathbf{Q}_p} (x) 
= \exp \bigl(\Trace_{\mathbf{Q}_q / \mathbf{Q}_p} (\log (x))\bigr).
\end{equation}

\section{Exponential}

\subsection{Definition}

For $x \in \mathbf{Z}_q$ with $\ord_p(x) \geq 2$ or $\ord_p(x) \geq 1$ 
as $p=2$ or $p > 2$, respectively, the $p$-adic exponential functions is 
defined via 
\begin{equation}
\exp(x) = \sum_{i = 0}^{\infty} \frac{x^i}{i!}.
\end{equation}
In order to compute $\exp(x) \bmod{p^N}$, using that for positive 
integers~$z$, we have
\begin{equation}
\ord_p(z!) = \frac{z - s_p(z)}{p - 1} \leq \frac{z}{p - 1}
\end{equation}
where $s_p(-)$ denote the sum of $p$-adic digits, we are led to compute 
the truncated series 
\begin{equation}
\exp(x) = \sum_{i = 0}^{n-1} \frac{x^i}{i!}
\end{equation}
where $n = \ceilbig{\bigl( (p-1)N - 1 \bigr) / \bigl( (p-1)v - 1 \bigr)}$.

For the sake of simplicity, we restrict our discussion to the case 
$q = p$, but remark that the approach as well as the analysis carry 
through to the case of unramified extensions.

Note that we require $\mathcal{O}(N)$ terms of the sum, 
and that when computing these iteratively for $i = 0, \dotsc, n-1$ 
each update step of the summand amounts to multiplication by $x / i$, 
which takes time $\mathcal{O}_p(M(N))$.  Thus, the entire computation 
takes time $\mathcal{O}_p(N M(N))$.

\subsection{Rectangular splitting}

The rectangular splitting algorithm evaluates the truncated series 
using the expression 
\begin{align}
\exp(x) & = \sum_{j=0}^{\ceil{n/B} - 1} 
            \biggl( \sum_{i=0}^{B-1} \frac{x^i}{(Bj + i)!} \biggr) x^{Bj} \\
        & = \sum_{j=0}^{\ceil{n/B} - 1} 
            \frac{1}{(B (j+1) - 1)!} \biggl( \sum_{i=0}^{B-1} \frac{(B (j+1) - 1)!}{(Bj + i)!} x^i \biggr) x^{Bj}
\end{align}
where $B = \floorts{\sqrt{n}}$.

This reduces the number of $p$-adic inversions as now the division in the 
inner sum is an exact integer division, but it does not lead to an asymptotic 
improvement.

[[TODO:  Include algorithm]]

\subsection{Binary splitting}

In this section, we describe Brent's binary splitting, or bit-burst 
algorithm~\citep{Brent1976} for computing the exponential function, 
adapted to the $p$-adic case.

\subsubsection{Exponential, exact rational}

Algorithm~\ref{alg:exp-bsplit} computes the sum 
\begin{equation}
(a-1)! x^{1-a} \sum_{i=a}^{b-1} \frac{x^i}{i!}
\end{equation}
as the rational number $T/Q$.

\begin{algorithm}
\caption{Computing the exponential as an exact rational}
\label{alg:exp-bsplit}
\begin{algorithmic}
\vspace{1mm}
\Require Integer~$x$, integers $1 \leq a < b$.
\Ensure  $P = x^{b-a}$, $Q = (b-1)! / (a-1)!$, $T = (b-1)! x^{1-a} \sum_{i=a}^{b-1} x^i / i!$.
\Procedure{ExpBSplit}{$P, Q, T, x, a, b$}
\If{$b - a = 1$}
\State $(P, Q, T) \gets (x, a, x)$
\ElsIf{$b - a = 2$}
\State $(P, Q, T) \gets (x^2, a (a + 1), x (a + 1) + x^2)$
\Else
\State $m \gets \floor{(a + b) / 2}$
\State \Call{ExpBSplit}{$P_0, Q_0, T_0, x, a, m$}
\State \Call{ExpBSplit}{$P_1, Q_1, T_1, x, m, b$}
\State $P \gets P_0 P_1$
\State $Q \gets Q_0 Q_1$
\State $T \gets T_0 Q_1 + P_0 T_1$
\EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

We can invoke this routine with $a = 1$, $b = n$ in order to compute 
$\sum_{i=1}^{n-1} x^i / i!$ as an exact rational.  Counting the 
number of multiplications and considering the sizes of the factors 
at the various levels of the recursion, we find that the complexity 
is given by $\mathcal{O}\bigl((M(n \log n) + M(n \log x) )\log n\bigr)$.

\subsubsection{Main part}

We now describe how to evaluate the truncated series 
$\sum_{i=0}^{n-1} x^i / i! \bmod{p^N}$ where we may assume 
that $0 \leq x < p^N$.  First, write 
\begin{equation}
x = \sum_{i=1}^{\ceil{\log_p N}} x_i
\end{equation}
with $0 \leq x_i < p^{2^i}$ and $\ord_p(x_i) \geq 2^{i-1}$.  Thus, 
\begin{equation}
\exp (x) = \prod_{i=1}^{\ceil{\log_p N}} \exp(x_i)
\end{equation}
and we observe that the computation of $\exp(x_i) \bmod p^N$ requires 
us to evaluate a sum of 
\begin{equation}
n_i \leq \frac{(p-1) N - 1}{(p-1) 2^{i-1} - 1} \leq \frac{N}{2^i}
\end{equation}
terms.

It follows that the overall complexity of this algorithm is 
$\mathcal{O}_p\bigl(M(N) (\log N)^2\bigr)$.

\section{Logarithm}

\subsection{Definition}

For $x \in \mathbf{Z}_q$ with $\ord_p(1 - x)$ at least $2$ or $1$ 
whenever $p = 2$ or $p > 2$, respectively, the $p$-adic logarithm 
function is defined as 
\begin{equation}
\log(x) = - \sum_{i=1}^{\infty} \frac{(1-x)^i}{i}.
\end{equation}

In order to compute $\log(x) \bmod p^N$, we need to consider all 
indices~$i$ such that $i \ord_p(1-x) - \ord_p(i) < N$.  For example, 
setting $n = \ceil{N/\ord_p(x)}$, 
\begin{equation*}
\log(x) = - \sum_{i=1}^{n-1} \frac{(1-x)^i}{i} \pmod{p^N}
\end{equation*}

As in the case of the exponential, since the number of terms 
is $\mathcal{O}(N)$, this truncated series can be evaluated 
in time $\mathcal{O}_p(M(N) N)$ using Horner's method.

\subsection{Rectangular splitting}

A significant constant factor improvement can be made by using 
a rectangular splitting algorithm, rewriting the sum as 
\begin{align}
\sum_{i=1}^{n-1} \frac{y^i}{i}
& = \sum_{j=0}^{\ceil{(n-1)/B} - 1} \Bigl( \sum_{i=1}^B \frac{y^i}{Bj + i} \Bigr) y^{Bj} \\
& = \sum_{j=0}^{\ceil{(n-1)/B} - 1} (Bj+1)_B^{-1} \Bigl( \sum_{i=1}^B \frac{(Bj+1)_B}{Bj + i} y^i \Bigr) y^{Bj}
\end{align}
where $B = \floor{\sqrt{n}}$ and for any integer~$z$ 
we let $z_B = \prod_{j=0}^{B-1} (z + j)$.  As the inner 
sum now features an exact integer division, this approach 
reduces the number of $p$-adic inversions to about $\sqrt{n}$.

[[TODO:  Algorithm]]

\subsection{Binary splitting}

\subsubsection{Logarithm, exact rational}

Algorithm~\ref{alg:log-bsplit} computes the sum 
\begin{equation}
(a-1)! y^{1-a} \sum_{i=a}^{b-1} \frac{y^i}{i}
\end{equation}
as the rational number $T/Q$.

\begin{algorithm}
\caption{Computing the  logarithm as an exact rational}
\label{alg:log-bsplit}
\begin{algorithmic}
\vspace{1mm}
\Require Integer~$y$, integers $1 \leq a < b$.
\Ensure  $P = y^{b-a}$, $Q = (b-1)! / (a-1)!$, $T = (b-1)! y^{1-a} \sum_{i=a}^{b-1} y^i / i$.
\Procedure{LogBSplit}{$P, Q, T, y, a, b$}
\If{$b - a = 1$}
\State $(P, Q, T) \gets (y, a, y)$
\ElsIf{$b - a = 2$}
\State $(P, Q, T) \gets (y^2, a (a + 1), y (a + 1) + y^2 a)$
\Else
\State $m \gets \floor{(a + b) / 2}$
\State \Call{LogBSplit}{$P_0, Q_0, T_0, y, a, m$}
\State \Call{LogBSplit}{$P_1, Q_1, T_1, y, m, b$}
\State $P \gets P_0 P_1$
\State $Q \gets Q_0 Q_1$
\State $T \gets T_0 Q_1 + T_1 P_0 Q_0$
\EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

We can invoke this routine with $a = 1$, $b = n$ in order to compute 
$\sum_{i=0}^{n-1} y^i / i$ as an exact rational.  Counting the 
number of multiplications and considering the sizes of the factors 
at the various levels of the recursion, we find that the complexity 
is given by $\mathcal{O}\bigl((M(n \log n) + M(n \log y) )\log n\bigr)$.

\subsubsection{Main part}

We can employ the same idea as in the case of the exponential 
function, relying on the expression 
\begin{equation}
\log(1 + x + x') = \log(1 + x) + \log \Bigl(1 + \frac{x'}{1+x}\Bigr).
\end{equation}

